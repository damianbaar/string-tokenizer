{
  "name": "string-tokenizer",
  "version": "0.0.6",
  "description": "Simple string tokenizer, to make RegExps less painful.",
  "main": "src/index.js",
  "scripts": {
    "test": "grunt test",
    "build": "grunt dev",
    "example": "node example"
  },
  "browser": {
    "main": "./dist/string-tokenizer.js"
  },
  "author": "Damian Baar <damian.baar@gmail.com> (http://github.com/damianbaar)",
  "license": "ISC",
  "dependencies": {
    "array-last": "^1.0.2",
    "lodash": "^3.7.0",
    "object-assign": "^2.0.0",
    "object-keys": "^1.0.3",
    "object-values": "^1.0.0",
    "re-define-include-external": "^0.4.1",
    "uniq": "^1.0.1"
  },
  "devDependencies": {
    "chai": "^2.2.0",
    "grunt": "^0.4.5",
    "grunt-contrib-watch": "^0.6.1",
    "grunt-mocha-test": "^0.12.7",
    "grunt-re-define": "^0.5.3",
    "mocha": "^2.2.4",
    "re-define-include-external": "^0.3.5"
  }
}
